[2024-01-27T17:53:02.543+0100] {processor.py:161} INFO - Started process (PID=8277) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:53:02.546+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:53:02.547+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:53:02.547+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:53:02.749+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:53:02.805+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:53:02.804+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:53:02.910+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:53:02.910+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:53:03.101+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.565 seconds
[2024-01-27T17:54:20.684+0100] {processor.py:161} INFO - Started process (PID=8345) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:54:20.687+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:54:20.688+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:54:20.688+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:54:20.699+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:54:20.798+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:54:20.798+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:54:20.817+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:54:20.817+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:54:21.215+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.534 seconds
[2024-01-27T17:55:01.669+0100] {processor.py:161} INFO - Started process (PID=8389) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:55:01.671+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:55:01.673+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:55:01.672+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:55:01.683+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:55:01.707+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:55:01.707+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:55:01.732+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:55:01.731+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:55:01.962+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.305 seconds
[2024-01-27T17:55:36.167+0100] {processor.py:161} INFO - Started process (PID=8417) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:55:36.173+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:55:36.174+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:55:36.174+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:55:36.184+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:55:36.208+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:55:36.207+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:55:36.246+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:55:36.245+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:55:36.364+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.200 seconds
[2024-01-27T17:56:13.452+0100] {processor.py:161} INFO - Started process (PID=8450) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:56:13.455+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:56:13.459+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:56:13.459+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:56:13.510+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:56:13.616+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:56:13.612+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:56:13.650+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:56:13.650+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:56:13.764+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.317 seconds
[2024-01-27T17:56:53.494+0100] {processor.py:161} INFO - Started process (PID=8480) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:56:53.498+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:56:53.500+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:56:53.499+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:56:53.515+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:56:53.539+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:56:53.539+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:56:53.583+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:56:53.583+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:56:53.831+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.344 seconds
[2024-01-27T17:57:28.898+0100] {processor.py:161} INFO - Started process (PID=8522) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:57:28.901+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:57:28.908+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:57:28.907+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:57:28.934+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:57:28.955+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:57:28.955+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:57:29.020+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:57:29.020+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:57:29.066+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.173 seconds
[2024-01-27T17:58:05.185+0100] {processor.py:161} INFO - Started process (PID=8567) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:58:05.188+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:58:05.189+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:58:05.189+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:58:05.205+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:58:05.229+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:58:05.229+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:58:05.256+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:58:05.256+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:58:05.302+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.121 seconds
[2024-01-27T17:58:43.020+0100] {processor.py:161} INFO - Started process (PID=8651) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:58:43.052+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:58:43.081+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:58:43.061+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:58:43.115+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:58:43.210+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:58:43.209+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:58:43.349+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:58:43.349+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:58:43.443+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.444 seconds
[2024-01-27T17:59:19.608+0100] {processor.py:161} INFO - Started process (PID=8678) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:59:19.612+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:59:19.619+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:59:19.618+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:59:19.635+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:59:19.664+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:59:19.664+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:59:19.695+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:59:19.695+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:59:19.833+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.229 seconds
[2024-01-27T17:59:55.444+0100] {processor.py:161} INFO - Started process (PID=8714) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:59:55.504+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T17:59:55.515+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:59:55.514+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:59:55.547+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T17:59:55.622+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:59:55.621+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T17:59:55.671+0100] {logging_mixin.py:188} INFO - [2024-01-27T17:59:55.671+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T17:59:56.018+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.587 seconds
[2024-01-27T18:00:31.238+0100] {processor.py:161} INFO - Started process (PID=8741) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:00:31.265+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:00:31.267+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:00:31.266+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:00:31.297+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:00:31.367+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:00:31.366+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:00:31.417+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:00:31.417+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:00:31.538+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.308 seconds
[2024-01-27T18:01:05.687+0100] {processor.py:161} INFO - Started process (PID=8776) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:01:05.718+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:01:05.719+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:01:05.719+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:01:05.777+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:01:05.802+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:01:05.802+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:01:05.842+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:01:05.842+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:01:05.934+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.251 seconds
[2024-01-27T18:01:41.642+0100] {processor.py:161} INFO - Started process (PID=8805) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:01:41.646+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:01:41.647+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:01:41.647+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:01:41.673+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:01:41.695+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:01:41.695+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:01:41.720+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:01:41.720+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:01:41.809+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.173 seconds
[2024-01-27T18:02:49.751+0100] {processor.py:161} INFO - Started process (PID=8851) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:02:49.756+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:02:49.765+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:02:49.764+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:02:49.850+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:02:49.951+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:02:49.951+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:02:50.156+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:02:50.155+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:02:50.804+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.059 seconds
[2024-01-27T18:04:25.487+0100] {processor.py:161} INFO - Started process (PID=8903) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:04:25.548+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:04:25.550+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:04:25.549+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:04:25.637+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:04:25.707+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:04:25.707+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:04:25.901+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:04:25.901+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:04:26.625+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.173 seconds
[2024-01-27T18:06:04.947+0100] {processor.py:161} INFO - Started process (PID=8952) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:06:04.980+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:06:04.990+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:06:04.989+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:06:05.049+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:06:05.213+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:06:05.213+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:06:05.410+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:06:05.409+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:06:05.744+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.830 seconds
[2024-01-27T18:08:08.902+0100] {processor.py:161} INFO - Started process (PID=9011) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:08:08.915+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:08:08.917+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:08:08.917+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:08:08.931+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:08:08.959+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:08:08.959+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:08:08.990+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:08:08.990+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:08:09.804+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.912 seconds
[2024-01-27T18:09:59.526+0100] {processor.py:161} INFO - Started process (PID=9079) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:09:59.619+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:09:59.620+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:09:59.620+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:09:59.680+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:09:59.817+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:09:59.817+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:09:59.890+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:09:59.890+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:10:00.214+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.730 seconds
[2024-01-27T18:11:43.340+0100] {processor.py:161} INFO - Started process (PID=9166) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:11:43.371+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:11:43.379+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:11:43.378+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:11:43.394+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:11:43.434+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:11:43.434+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:11:43.538+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:11:43.538+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:11:44.162+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.864 seconds
[2024-01-27T18:13:23.035+0100] {processor.py:161} INFO - Started process (PID=9224) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:13:23.068+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:13:23.071+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:13:23.070+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:13:23.104+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:13:23.215+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:13:23.215+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:13:23.383+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:13:23.382+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:13:24.205+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.186 seconds
[2024-01-27T18:15:08.451+0100] {processor.py:161} INFO - Started process (PID=9273) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:15:08.483+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:15:08.486+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:15:08.485+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:15:08.536+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:15:08.680+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:15:08.672+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:15:08.803+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:15:08.803+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:15:09.182+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.770 seconds
[2024-01-27T18:16:53.976+0100] {processor.py:161} INFO - Started process (PID=9323) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:16:54.010+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:16:54.025+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:16:54.024+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:16:54.124+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:16:54.256+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:16:54.256+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:16:54.404+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:16:54.403+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:16:54.853+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.981 seconds
[2024-01-27T18:18:39.016+0100] {processor.py:161} INFO - Started process (PID=9403) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:18:39.046+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:18:39.054+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:18:39.053+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:18:39.097+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:18:39.204+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:18:39.203+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:18:39.348+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:18:39.347+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:18:39.926+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.918 seconds
[2024-01-27T18:20:26.946+0100] {processor.py:161} INFO - Started process (PID=9534) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:20:26.972+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:20:26.994+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:20:26.973+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:20:27.121+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:20:27.334+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:20:27.334+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:20:27.518+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:20:27.510+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:20:28.073+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.142 seconds
[2024-01-27T18:22:14.684+0100] {processor.py:161} INFO - Started process (PID=9594) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:22:14.695+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:22:14.699+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:22:14.698+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:22:14.761+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:22:14.849+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:22:14.849+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:22:14.949+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:22:14.949+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:22:15.604+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.941 seconds
[2024-01-27T18:24:13.653+0100] {processor.py:161} INFO - Started process (PID=9721) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:24:13.663+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:24:13.666+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:24:13.665+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:24:13.725+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:24:13.892+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:24:13.891+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:24:14.027+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:24:14.027+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:24:14.886+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.241 seconds
[2024-01-27T18:26:10.429+0100] {processor.py:161} INFO - Started process (PID=9794) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:26:10.497+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:26:10.507+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:26:10.498+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:26:10.604+0100] {processor.py:840} INFO - DAG(s) 'meteo' retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:26:10.737+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:26:10.736+0100] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-27T18:26:10.964+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:26:10.964+0100] {dag.py:3820} INFO - Setting next_dagrun for meteo to 2022-01-01T00:00:00+00:00, run_after=2022-01-02T00:00:00+00:00
[2024-01-27T18:26:11.774+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.379 seconds
[2024-01-27T18:32:22.161+0100] {processor.py:161} INFO - Started process (PID=9966) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:32:22.283+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:32:22.307+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:32:22.306+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:32:22.481+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:32:22.465+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 22, in <module>
    start_task = DummyOperator(
NameError: name 'DummyOperator' is not defined
[2024-01-27T18:32:22.482+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:32:23.414+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 1.272 seconds
[2024-01-27T18:34:50.204+0100] {processor.py:161} INFO - Started process (PID=10046) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:34:50.234+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:34:50.247+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:34:50.235+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:34:50.286+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:34:50.285+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 33, in <module>
    end_task = DummyOperator(
NameError: name 'DummyOperator' is not defined
[2024-01-27T18:34:50.291+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:34:50.736+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 0.555 seconds
[2024-01-27T18:36:29.085+0100] {processor.py:161} INFO - Started process (PID=10116) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:36:29.133+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:36:29.165+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:36:29.163+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:36:32.255+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:36:32.246+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:36:32.277+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:36:32.269+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:36:34.202+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:36:34.200+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:36:34.205+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:36:34.214+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:36:34.213+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 33, in <module>
    end_task = DummyOperator(
NameError: name 'DummyOperator' is not defined
[2024-01-27T18:36:34.218+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:36:34.795+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 5.759 seconds
[2024-01-27T18:38:15.664+0100] {processor.py:161} INFO - Started process (PID=10186) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:38:15.741+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:38:15.766+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:38:15.765+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:38:17.850+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:38:17.848+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:38:17.851+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:38:17.851+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:38:18.298+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:38:18.296+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:38:18.298+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:38:18.301+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:38:18.300+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 28, in <module>
    python_callable=sauvegarder_sur_hdfs,
NameError: name 'sauvegarder_' is not defined
[2024-01-27T18:38:18.302+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:38:18.861+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.229 seconds
[2024-01-27T18:40:04.378+0100] {processor.py:161} INFO - Started process (PID=10241) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:40:04.443+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:40:04.468+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:40:04.462+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:40:06.662+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:40:06.661+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:40:06.663+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:40:06.662+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:40:07.915+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:40:07.348+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:40:07.917+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:40:07.932+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:40:07.930+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 34, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:40:07.944+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:40:08.624+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 4.279 seconds
[2024-01-27T18:41:49.215+0100] {processor.py:161} INFO - Started process (PID=10309) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:41:49.267+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:41:49.269+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:41:49.268+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:41:51.346+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:41:51.345+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:41:51.346+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:41:51.346+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:41:51.840+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:41:51.823+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:41:51.846+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:41:51.870+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:41:51.851+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 35, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:41:51.871+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:41:52.104+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 2.922 seconds
[2024-01-27T18:43:44.261+0100] {processor.py:161} INFO - Started process (PID=10372) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:43:44.315+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:43:44.328+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:43:44.327+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:43:46.934+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:43:46.928+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:43:46.956+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:43:46.955+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:43:47.333+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:43:47.322+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:43:47.366+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:43:47.423+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:43:47.414+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 35, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:43:47.424+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:43:47.931+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.676 seconds
[2024-01-27T18:45:42.844+0100] {processor.py:161} INFO - Started process (PID=10439) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:45:42.893+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:45:42.894+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:45:42.894+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:45:45.158+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:45:45.139+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:45:45.159+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:45:45.159+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:45:45.510+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:45:45.508+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:45:45.518+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:45:45.553+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:45:45.532+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:45:45.554+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:45:46.188+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.367 seconds
[2024-01-27T18:47:33.462+0100] {processor.py:161} INFO - Started process (PID=10595) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:47:33.503+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:47:33.511+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:47:33.504+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:47:35.998+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:47:35.997+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:47:35.999+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:47:35.998+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:47:36.322+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:47:36.318+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:47:36.325+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:47:36.338+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:47:36.337+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:47:36.339+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:47:36.549+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.095 seconds
[2024-01-27T18:49:12.528+0100] {processor.py:161} INFO - Started process (PID=10672) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:49:12.544+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:49:12.546+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:49:12.545+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:49:14.618+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:49:14.611+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:49:14.632+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:49:14.631+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:49:15.187+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:49:15.175+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:49:15.188+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:49:15.197+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:49:15.194+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:49:15.198+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:49:15.686+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.181 seconds
[2024-01-27T18:50:50.799+0100] {processor.py:161} INFO - Started process (PID=10727) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:50:50.859+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:50:50.861+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:50:50.860+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:50:53.110+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:50:53.108+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:50:53.110+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:50:53.110+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:50:53.962+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:50:53.952+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:50:54.109+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:50:54.154+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:50:54.153+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:50:54.201+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:50:54.787+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 4.050 seconds
[2024-01-27T18:52:45.933+0100] {processor.py:161} INFO - Started process (PID=10786) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:52:45.974+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:52:45.976+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:52:45.975+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:52:49.015+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:52:49.004+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:52:49.042+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:52:49.042+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:52:50.239+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:52:50.226+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:52:50.265+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:52:50.301+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:52:50.299+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:52:50.302+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:52:51.081+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 5.208 seconds
[2024-01-27T18:55:18.970+0100] {processor.py:161} INFO - Started process (PID=10843) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:55:19.173+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:55:19.184+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:55:19.174+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:55:22.159+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:55:22.157+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:55:22.159+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:55:22.159+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:55:22.748+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:55:22.645+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:55:22.751+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T18:55:22.782+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:55:22.771+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:55:22.783+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:55:23.557+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 4.637 seconds
[2024-01-27T18:57:57.594+0100] {processor.py:161} INFO - Started process (PID=10924) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:57:57.657+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T18:57:57.679+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:57:57.673+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:57:59.619+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:57:59.589+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T18:57:59.649+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:57:59.648+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T18:58:00.440+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:58:00.431+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:58:00.446+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T18:58:00.456+0100] {logging_mixin.py:188} INFO - [2024-01-27T18:58:00.452+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T18:58:00.459+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T18:58:01.262+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.742 seconds
[2024-01-27T19:00:03.139+0100] {processor.py:161} INFO - Started process (PID=10980) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:00:03.194+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T19:00:03.205+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:00:03.204+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:00:06.474+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:00:06.472+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T19:00:06.475+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:00:06.474+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T19:00:07.302+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:00:07.292+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T19:00:07.329+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : /user/Datalake/raw/temperature/2024-01-27.json for client 127.0.0.1 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2732)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2625)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:807)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:496)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
[2024-01-27T19:00:07.372+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:00:07.350+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T19:00:07.380+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:00:07.952+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 4.843 seconds
[2024-01-27T19:02:12.062+0100] {processor.py:161} INFO - Started process (PID=11036) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:02:12.109+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T19:02:12.133+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:02:12.124+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:02:14.402+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:02:14.400+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T19:02:14.465+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:02:14.402+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T19:02:14.922+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:02:14.866+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:02:14.942+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:02:15.003+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:02:14.996+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T19:02:15.015+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:02:15.336+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.303 seconds
[2024-01-27T19:04:29.725+0100] {processor.py:161} INFO - Started process (PID=11093) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:04:29.764+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T19:04:29.780+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:04:29.779+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:04:32.041+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:04:32.040+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T19:04:32.042+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:04:32.042+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T19:04:32.833+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:04:32.803+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:04:32.859+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:04:32.894+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:04:32.887+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T19:04:32.917+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:04:33.457+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.782 seconds
[2024-01-27T19:06:42.314+0100] {processor.py:161} INFO - Started process (PID=11147) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:06:42.364+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T19:06:42.373+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:06:42.372+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:06:44.427+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:06:44.426+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T19:06:44.429+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:06:44.427+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T19:06:45.064+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:06:45.001+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:06:45.067+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:06:45.079+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:06:45.077+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T19:06:45.081+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:06:45.686+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 3.440 seconds
[2024-01-27T19:08:56.744+0100] {processor.py:161} INFO - Started process (PID=11206) to work on /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:08:56.754+0100] {processor.py:830} INFO - Processing file /home/ubuntu/airflow/dags/meteo.py for tasks to queue
[2024-01-27T19:08:56.810+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:08:56.794+0100] {dagbag.py:538} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:09:06.436+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:09:06.435+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-01-27T19:09:06.438+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:09:06.438+0100] {client.py:496} INFO - Writing to '/user/Datalake/raw/temperature/2024-01-27.json'.
[2024-01-27T19:09:07.312+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:09:07.253+0100] {util.py:78} ERROR - Exception in child.
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 414, in _make_request
    conn.request_chunked(method, url, **httplib_request_kw)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/urllib3/connection.py", line 280, in request_chunked
    self.send(to_send)
  File "/usr/lib/python3.10/http/client.py", line 999, in send
    self.sock.sendall(data)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/util.py", line 76, in consumer
    self._consumer(data)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 509, in consumer
    res = self._request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/hdfs/client.py", line 209, in _request
    return self._session.request(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:09:07.313+0100] {logging_mixin.py:188} INFO - Une erreur s'est produite : ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
[2024-01-27T19:09:07.336+0100] {logging_mixin.py:188} INFO - [2024-01-27T19:09:07.332+0100] {dagbag.py:348} ERROR - Failed to import: /home/ubuntu/airflow/dags/meteo.py
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/airflow/dags/meteo.py", line 37, in <module>
    start_task >> python_task >> end_task
NameError: name 'start_task' is not defined
[2024-01-27T19:09:07.345+0100] {processor.py:842} WARNING - No viable dags retrieved from /home/ubuntu/airflow/dags/meteo.py
[2024-01-27T19:09:07.937+0100] {processor.py:183} INFO - Processing /home/ubuntu/airflow/dags/meteo.py took 11.202 seconds
